{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, Dense, Activation\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = open('results.txt','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha(text):\n",
    "    return ''.join(i for i in text if i.isalpha() or i == ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5968 total characters and 28 unique characters in your data.\n"
     ]
    }
   ],
   "source": [
    "pokemon_df = pd.read_csv('data/pokemon.csv')\n",
    "pokemon_names = pokemon_df.name.apply(remove_non_alpha).str.lower().tolist()\n",
    "data = ''.join(pokemon_names)\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: 'Ã©'}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Format\n",
    "Expected format: (batch_size, timesteps, input_dim)\n",
    "Source: https://keras.io/layers/recurrent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crabominable 12\n"
     ]
    }
   ],
   "source": [
    "SEQ_LENGTH = len(max(pokemon_names, key=len))\n",
    "print(max(pokemon_names, key=len), SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(data) // SEQ_LENGTH\n",
    "X = np.zeros((batch_size, SEQ_LENGTH, vocab_size))\n",
    "y = np.zeros((batch_size, SEQ_LENGTH, vocab_size))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    X_sequence = data[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_to_ix[val] for val in X_sequence]\n",
    "    \n",
    "    input_sequence = np.zeros((SEQ_LENGTH, vocab_size))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    y_sequence = data[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_to_ix[val] for val in y_sequence]\n",
    "    \n",
    "    target_sequence = np.zeros((SEQ_LENGTH, vocab_size))\n",
    "    new_length = len(y_sequence)\n",
    "    for j in range(new_length):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(497, 12, 28) (497, 12, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(vocab_size, input_shape=(None, vocab_size), dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(LSTM(vocab_size, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(LSTM(vocab_size, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('<some-prev-day>.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, max_length):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(1, vocab_size)] # don't start off with space\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, max_length, vocab_size))\n",
    "    for i in range(max_length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\", file=results)\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    print('\\n', file=results)\n",
    "    model.fit(X, y, batch_size=50, verbose=0, epochs=1) # show progress\n",
    "    print(i, file=results)\n",
    "    # print 5 pokemon names each time\n",
    "    for j in range(5):\n",
    "        generate_text(model, np.random.randint(3, SEQ_LENGTH))\n",
    "        print('\\n', file=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "model.save_weights('{save_name}.hdf5'.format(save_name=now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
